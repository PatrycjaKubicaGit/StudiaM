{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7719d0-0dea-42ff-b4ac-657ba6e01576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane mają 157 znaków, 27 unikalnych.\n",
      "Rozpoczynam trening...\n",
      "\n",
      "--- Iteracja 0, Loss: 82.3958 ---\n",
      "Generowany tekst: mElhcnsvclaseeeeuiochmhlhmec ths shkcce)ka,hhuhc nhEctrich hlhawi ile)wuehnxhx(hick mwiwiacpcnhhcceweohchhaohlhlcu ciihch wehhch siwthcefmnchw dtciehhashh ehnihh b hchhk,chhedow achwhlcwwewsishwhhchwh\n",
      "\n",
      "--- Iteracja 1000, Loss: 35.5367 ---\n",
      "Generowany tekst: pee, as well as other mappings of cotion, translation between (natural) languages, as well as other mappings of bettransision between is of betweec (nas tin donurecgs vis ee (natural) languages, as we\n",
      "\n",
      "--- Iteracja 2000, Loss: 13.2453 ---\n",
      "Generowany tekst: ion, translation betwell ation between (natural) doneecnssplecof iomeudr s other mappings of eetion tramplat s oncer mamwet nn(oneechision, translation between (natural) languagea, as well as other ma\n",
      "\n",
      "--- Iteracja 3000, Loss: 4.9259 ---\n",
      "Generowany tekst: tion  is, in well as other mappings of bettranslation, torel is well as other mappings of betnratural) languages, as don in well as other mappings of othis is done include coner maoguagea, is well as \n",
      "\n",
      "--- Iteracja 4000, Loss: 1.8465 ---\n",
      "Generowany tekst: ude nnspu at of beterathis iondons lasweech this is well at on between (natural) ianguages, as well as other gaswein whichithis is done include speech recognition, computer vision, translation between\n",
      "\n",
      "--- Iteracja 5000, Loss: 0.7046 ---\n",
      "Generowany tekst: ion, trrnslation, thrnisaon bdn done include speech recognition, computer vision, translation between (natural) languages, as well as other mappings of bettranslation between (natural) languages, as w\n",
      "\n",
      "--- Iteracja 6000, Loss: 0.2792 ---\n",
      "Generowany tekst: s is done include speech recognition, conpute r vis inawell as onner mappinsson becothico, iiompee r spon etreech maothigs this is well as other maopnincothir lation, translation between (natural) lan\n",
      "\n",
      "--- Iteracja 7000, Loss: 0.1192 ---\n",
      "Generowany tekst: uale coneech asion, tramplat gs of cellgn ns san incbelch vis inawell gs of cognss, ation between (natural) languages, as well as other mappings of hetionmilanguages, as well as other mappings of bett\n",
      "\n",
      "--- Iteracja 8000, Loss: 0.0578 ---\n",
      "Generowany tekst: ion, trrnslation, translation between (natural) languages, as well as other mappings of eetinnluagnspeech recognition, translation between (natural) languages, as well as other mappings of bettranslat\n",
      "\n",
      "Osiągnięto wymaganą dokładność (Loss < 0.1). Koniec treningu.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 1. Przygotowanie danych (Wariant 2) ---\n",
    "data = \"Example tasks in which this is done include speech recognition, computer vision, translation between (natural) languages, as well as other mappings of inputs\"\n",
    "\n",
    "chars = list(set(data))\n",
    "data_size, X_size = len(data), len(chars)\n",
    "print(f\"Dane mają {data_size} znaków, {X_size} unikalnych.\")\n",
    "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# --- 2. Stałe i Hiperparametry ---\n",
    "# Zmieniono H_size z 10 na 64, aby sieć mogła osiągnąć dokładność 0.1 na dłuższym tekście\n",
    "H_size = 64          \n",
    "T_steps = 25         \n",
    "learning_rate = 1e-1 \n",
    "weight_sd = 0.1      \n",
    "z_size = H_size + X_size\n",
    "\n",
    "# --- 3. Funkcje aktywacji ---\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y * (1 - y)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dtanh(y):\n",
    "    return 1 - y * y\n",
    "\n",
    "# --- 4. Inicjalizacja Parametrów ---\n",
    "class Param:\n",
    "    def __init__(self, name, value):\n",
    "        self.name = name\n",
    "        self.v = value                \n",
    "        self.d = np.zeros_like(value) \n",
    "        self.m = np.zeros_like(value) \n",
    "\n",
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.W_f = Param('W_f', np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_f = Param('b_f', np.zeros((H_size, 1)))\n",
    "        \n",
    "        self.W_i = Param('W_i', np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_i = Param('b_i', np.zeros((H_size, 1)))\n",
    "        \n",
    "        self.W_C = Param('W_C', np.random.randn(H_size, z_size) * weight_sd)\n",
    "        self.b_C = Param('b_C', np.zeros((H_size, 1)))\n",
    "        \n",
    "        self.W_o = Param('W_o', np.random.randn(H_size, z_size) * weight_sd + 0.5)\n",
    "        self.b_o = Param('b_o', np.zeros((H_size, 1)))\n",
    "        \n",
    "        self.W_v = Param('W_v', np.random.randn(X_size, H_size) * weight_sd)\n",
    "        self.b_v = Param('b_v', np.zeros((X_size, 1)))\n",
    "\n",
    "    def all(self):\n",
    "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
    "                self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
    "\n",
    "parameters = Parameters()\n",
    "\n",
    "# --- 5. Forward Pass ---\n",
    "def forward(x, h_prev, C_prev, p=parameters):\n",
    "    z = np.vstack((h_prev, x))\n",
    "    \n",
    "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
    "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
    "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
    "    \n",
    "    C = f * C_prev + i * C_bar\n",
    "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
    "    h = o * tanh(C)\n",
    "    \n",
    "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
    "    y = np.exp(v) / np.sum(np.exp(v))\n",
    "    \n",
    "    return z, f, i, C_bar, C, o, h, v, y\n",
    "\n",
    "# --- 6. Backward Pass ---\n",
    "def backward(target, dh_next, dC_next, C_prev, z, f, i, C_bar, C, o, h, v, y, p=parameters):\n",
    "    dv = np.copy(y)\n",
    "    dv[target] -= 1\n",
    "    \n",
    "    p.W_v.d += np.dot(dv, h.T)\n",
    "    p.b_v.d += dv\n",
    "    \n",
    "    dh = np.dot(p.W_v.v.T, dv)\n",
    "    dh += dh_next\n",
    "    \n",
    "    do = dh * tanh(C)\n",
    "    do = dsigmoid(o) * do\n",
    "    p.W_o.d += np.dot(do, z.T)\n",
    "    p.b_o.d += do\n",
    "    \n",
    "    dC = np.copy(dC_next)\n",
    "    dC += dh * o * dtanh(tanh(C))\n",
    "    \n",
    "    dC_bar = dC * i\n",
    "    dC_bar = dtanh(C_bar) * dC_bar\n",
    "    p.W_C.d += np.dot(dC_bar, z.T)\n",
    "    p.b_C.d += dC_bar\n",
    "    \n",
    "    di = dC * C_bar\n",
    "    di = dsigmoid(i) * di\n",
    "    p.W_i.d += np.dot(di, z.T)\n",
    "    p.b_i.d += di\n",
    "    \n",
    "    df = dC * C_prev\n",
    "    df = dsigmoid(f) * df\n",
    "    p.W_f.d += np.dot(df, z.T)\n",
    "    p.b_f.d += df\n",
    "    \n",
    "    dz = (np.dot(p.W_f.v.T, df) + \n",
    "          np.dot(p.W_i.v.T, di) + \n",
    "          np.dot(p.W_C.v.T, dC_bar) + \n",
    "          np.dot(p.W_o.v.T, do))\n",
    "    \n",
    "    dh_prev = dz[:H_size, :]\n",
    "    dC_prev = f * dC\n",
    "    \n",
    "    return dh_prev, dC_prev\n",
    "\n",
    "# --- 7. Funkcje pomocnicze ---\n",
    "def clear_gradients(params=parameters):\n",
    "    for p in params.all():\n",
    "        p.d.fill(0)\n",
    "\n",
    "def clip_gradients(params=parameters):\n",
    "    for p in params.all():\n",
    "        np.clip(p.d, -1, 1, out=p.d)\n",
    "\n",
    "def update_parameters(params=parameters):\n",
    "    for p in params.all():\n",
    "        p.m += p.d * p.d\n",
    "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))\n",
    "\n",
    "# --- 8. Wrapper Forward-Backward ---\n",
    "def forward_backward(inputs, targets, h_prev, C_prev):\n",
    "    x_s, z_s, f_s, i_s = {}, {}, {}, {}\n",
    "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
    "    v_s, y_s = {}, {}\n",
    "    \n",
    "    h_s[-1] = np.copy(h_prev)\n",
    "    C_s[-1] = np.copy(C_prev)\n",
    "    loss = 0\n",
    "    \n",
    "    for t in range(len(inputs)):\n",
    "        x_s[t] = np.zeros((X_size, 1))\n",
    "        x_s[t][inputs[t]] = 1\n",
    "        \n",
    "        (z_s[t], f_s[t], i_s[t], C_bar_s[t], C_s[t], o_s[t], h_s[t], v_s[t], y_s[t]) = \\\n",
    "            forward(x_s[t], h_s[t-1], C_s[t-1])\n",
    "            \n",
    "        loss += -np.log(y_s[t][targets[t], 0])\n",
    "        \n",
    "    clear_gradients()\n",
    "    dh_next = np.zeros_like(h_s[0])\n",
    "    dC_next = np.zeros_like(C_s[0])\n",
    "    \n",
    "    for t in reversed(range(len(inputs))):\n",
    "        dh_next, dC_next = backward(\n",
    "            target=targets[t], dh_next=dh_next, dC_next=dC_next, C_prev=C_s[t-1],\n",
    "            z=z_s[t], f=f_s[t], i=i_s[t], C_bar=C_bar_s[t], C=C_s[t], o=o_s[t], \n",
    "            h=h_s[t], v=v_s[t], y=y_s[t]\n",
    "        )\n",
    "        \n",
    "    clip_gradients()\n",
    "    return loss, h_s[len(inputs)-1], C_s[len(inputs)-1]\n",
    "\n",
    "# --- 9. Generowanie tekstu ---\n",
    "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
    "    x = np.zeros((X_size, 1))\n",
    "    x[first_char_idx] = 1\n",
    "    h = h_prev\n",
    "    C = C_prev\n",
    "    indexes = []\n",
    "    \n",
    "    for t in range(sentence_length):\n",
    "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
    "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
    "        x = np.zeros((X_size, 1))\n",
    "        x[idx] = 1\n",
    "        indexes.append(idx)\n",
    "        \n",
    "    return indexes\n",
    "\n",
    "# --- 10. Pętla treningowa ---\n",
    "print(\"Rozpoczynam trening...\")\n",
    "iter_num = 0\n",
    "smooth_loss = -np.log(1.0/X_size) * T_steps\n",
    "pointer = 0\n",
    "\n",
    "g_h_prev = np.zeros((H_size, 1))\n",
    "g_C_prev = np.zeros((H_size, 1))\n",
    "\n",
    "while True:\n",
    "    if pointer + T_steps >= len(data) or iter_num == 0:\n",
    "        g_h_prev = np.zeros((H_size, 1))\n",
    "        g_C_prev = np.zeros((H_size, 1))\n",
    "        pointer = 0\n",
    "\n",
    "    inputs = [char_to_idx[ch] for ch in data[pointer: pointer + T_steps]]\n",
    "    targets = [char_to_idx[ch] for ch in data[pointer + 1: pointer + T_steps + 1]]\n",
    "\n",
    "    loss, g_h_prev, g_C_prev = forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "    update_parameters()\n",
    "\n",
    "    if iter_num % 1000 == 0:\n",
    "        sample_idx = sample(g_h_prev, g_C_prev, inputs[0], 200)\n",
    "        txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
    "        print(f\"\\n--- Iteracja {iter_num}, Loss: {smooth_loss:.4f} ---\")\n",
    "        print(f\"Generowany tekst: {txt}\")\n",
    "        \n",
    "        # Warunek z zadania: dokładność 0.1\n",
    "        if smooth_loss < 0.1: \n",
    "            print(\"\\nOsiągnięto wymaganą dokładność (Loss < 0.1). Koniec treningu.\")\n",
    "            break\n",
    "\n",
    "    pointer += T_steps\n",
    "    iter_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09363794-e697-478b-aa26-227dffbe3ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
